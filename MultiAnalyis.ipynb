{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import subprocess\n",
    "import json\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "cc_algorithms = ['lia', 'olia', 'balia', 'wvegas', 'cubic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_all():\n",
    "    folder = './logs/'\n",
    "    for _ in range(8):\n",
    "        for dirpath, dirnames, filenames in os.walk(folder):\n",
    "            for d in filenames + dirnames:\n",
    "                if '-' in d:\n",
    "                    full_path = '{}/{}'.format(dirpath, d)\n",
    "                    os.rename(full_path, full_path.replace('-', '_'))\n",
    "rename_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON config files\n",
    "def load_config(topology):\n",
    "    file_name = './topologies/{}.json'.format(topology)\n",
    "    if not os.path.isfile(file_name):\n",
    "        print('JSON topology file not found! {}'.format(file_name))\n",
    "        return None\n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_iperf_pairings(topology):\n",
    "    config = load_config(topology)\n",
    "    pairs = []\n",
    "    for node in [node for node in config['nodes'] if node['id'].startswith('h')]:\n",
    "        if 'server' in node['properties']:\n",
    "            pairs.append((str(node['id']), str(node['properties']['server'])))\n",
    "\n",
    "    # make sure every host is included in some connection\n",
    "    hosts = itertools.chain.from_iterable(pairs)\n",
    "    for node in [node for node in config['nodes'] if node['id'].startswith('h')]:\n",
    "        if node['id'] not in hosts:\n",
    "            print('Host {} not contained in any host pairings!'.format(node))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def num_clients(topology):\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    return len(pairs)\n",
    "\n",
    "\n",
    "def confidence_interval(series, z=1.96):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval for a given series. Default is 95% confidence interval.\n",
    "    See https://en.wikipedia.org/wiki/Confidence_interval#Basic_steps for further values.\n",
    "    \"\"\"\n",
    "    stats = series.agg(['mean', 'count', 'std'])\n",
    "    return z*stats['std']/math.sqrt(stats['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO simplify and use in upper function to eliminate duplicat code\n",
    "def read_iperf_srv_tp_trace(folder, client, server, repetitions):\n",
    "    file_name = folder + '/{}_{}_iperf.csv'\n",
    "    \n",
    "    tp_dfs = pd.DataFrame()\n",
    "    for rep in range(repetitions):\n",
    "        ser_file = file_name.format(rep, server)\n",
    "            \n",
    "        with open(ser_file, 'r') as f:\n",
    "            content = f.read().replace('iperf3: interrupt - the server has terminated', '').strip().splitlines()\n",
    "            content = content[6:-4] # TODO replace with conditional cutting\n",
    "            df = pd.DataFrame([l.replace('[', '').replace(']','').split() for l in content],\n",
    "                             columns=['ID', 'Interval', 'Interval_unit', 'Transfer', 'Transfer_unit', 'Bandwidth', 'Bandwidth_unit'])\n",
    "            df['repetition'] = rep\n",
    "            tp_dfs = tp_dfs.append(df, ignore_index=True)\n",
    "            \n",
    "    tp_dfs['client'] = client\n",
    "    tp_dfs['server'] = server\n",
    "    tp_dfs['Interval_start'] = tp_dfs['Interval'].str.split('-').str[0].astype(float)\n",
    "    tp_dfs['Interval_end'] = tp_dfs['Interval'].str.split('-').str[1].astype(float)\n",
    "    tp_dfs['ID'] = pd.to_numeric(tp_dfs['ID'])\n",
    "    tp_dfs['Transfer'] = pd.to_numeric(tp_dfs['Transfer'])\n",
    "    tp_dfs['Bandwidth'] = pd.to_numeric(tp_dfs['Bandwidth'])\n",
    "    return tp_dfs\n",
    "\n",
    "    \n",
    "def read_pcap_csv(file_name):\n",
    "    df = pd.read_csv(file_name, delimiter='\\t')\n",
    "    # Note: puts rtt into [ms] instead of [s]\n",
    "    df['tcp.analysis.ack_rtt'] = df['tcp.analysis.ack_rtt'] * 1000\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_single_iperf_experiment_rtt(topology, ccs, rates, delays, store_info=True):\n",
    "    folder = './logs/{}/{}/{}/{}/'.format(topology, ccs, rates, delays)\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    cli_to_srv = {c: s for c, s in pairs}\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    if not os.path.exists(folder):\n",
    "        print('Attention, folder {} does not exist!'.format(folder))\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(folder):\n",
    "        client_tuples = [(name,) + extract_rep_host_name(name) for name in filenames]\n",
    "        client_tuples = [t for t in client_tuples if t[0].endswith('iperf_dump.csv')]\n",
    "        \n",
    "        # add each client as a rtt datapoint\n",
    "        for file_name, host_name, rep in client_tuples:\n",
    "            pcap = read_pcap_csv('{}/{}'.format(dirpath, file_name))\n",
    "            pcap['repetition'] = rep\n",
    "            pcap['host'] = host_name\n",
    "            df = df.append(pcap, ignore_index=True)\n",
    "            \n",
    "    df = df.dropna(subset=['tcp.analysis.ack_rtt'])\n",
    "    if store_info:\n",
    "        df['topology'] = topology\n",
    "        df['ccs'] = ccs\n",
    "        df['bw'] = rates\n",
    "        df['delays'] = delays\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_rep_host_name(filename):\n",
    "    \"\"\" Returns a tuple (host_name, rep) \"\"\"\n",
    "    rep_hname = filename.split('_')\n",
    "    return rep_hname[1], int(rep_hname[0])\n",
    "\n",
    "\n",
    "def read_single_iperf_goodput(folder, client_file):\n",
    "    with open('{}/{}'.format(folder, client_file), 'r') as f:\n",
    "        content = f.read()[-300:] \\\n",
    "                    .replace('iperf Done.', '') \\\n",
    "                    .replace('iperf3: interrupt - the server has terminated', '') \\\n",
    "                    .strip().splitlines()\n",
    "        recv_line = content[-1].split()\n",
    "        assert 'receiver' in recv_line\n",
    "        return float(recv_line[6])\n",
    "\n",
    "\n",
    "def load_single_iperf_experiment_tp(topology, ccs, rates, delays, store_info=True):\n",
    "    folder = './logs/{}/{}/{}/{}/'.format(topology, ccs, rates, delays)\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    cli_to_srv = {c: s for c, s in pairs}\n",
    "    \n",
    "    if not os.path.exists(folder):\n",
    "        print('Attention, folder {} does not exist!'.format(folder))\n",
    "        \n",
    "    columns = {}\n",
    "    for srv in cli_to_srv.values():\n",
    "        columns[srv + '_tp'] = {}\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(folder):\n",
    "        client_tuples = [(name,) + extract_rep_host_name(name) for name in filenames]\n",
    "        client_tuples = [t for t in client_tuples if t[0].endswith('iperf.csv') and t[1] in cli_to_srv.keys()]\n",
    "        \n",
    "        # add each client as a tp datapoint\n",
    "        for file_name, host_name, rep in client_tuples:\n",
    "            tp = read_single_iperf_goodput(dirpath, file_name)\n",
    "            srv_name = cli_to_srv[host_name]\n",
    "            columns[srv_name + '_tp'][rep] = tp\n",
    "    df = pd.DataFrame(columns)\n",
    "    df.index.name = 'rep'\n",
    "    if store_info:\n",
    "        df['topology'] = topology\n",
    "        df['ccs'] = ccs\n",
    "        df['bws'] = rates\n",
    "        df['delays'] = delays\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_iperf_experiments_new(topology, repetitions=3):\n",
    "    \"\"\"\n",
    "    Read in log data from experiments, every throughput should come out in [Mbps] and times in [ms].\n",
    "    One exception to this rule is the relative time since experiment start in the rtt trace.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk('./logs/{}'.format(topology)):\n",
    "        if dirnames:\n",
    "            continue\n",
    "        \n",
    "        # Leaf folder, read in files and analyze\n",
    "        # dirpath has form \"./logs/two_paths/cubic/25Mbps-9Mbps/10ms-10ms\"\n",
    "        dirpath_split = dirpath.split('/') # ['.', 'logs', 'two_paths', 'lia', '9Mbps-13Mbps', '10ms-10ms']\n",
    "        cc_name = dirpath_split[-3]\n",
    "        cc = cc_name\n",
    "        bw_name = dirpath_split[-2]\n",
    "        bws = bw_name.split('_')\n",
    "        de_name = dirpath_split[-1]\n",
    "        des = de_name.split('_')\n",
    "        \n",
    "        df_run = load_single_iperf_experiment_tp(topology, cc_name, bw_name, de_name, store_info=False)\n",
    "        df_run_rtt = read_single_iperf_experiment_rtt(topology, cc_name, bw_name, de_name, store_info=False)\n",
    "        \n",
    "        df_run_rtt = df_run_rtt.groupby(['repetition', 'host'])['tcp.analysis.ack_rtt'].mean()\n",
    "\n",
    "        # read in data for pairings\n",
    "        row = {'cc': cc}\n",
    "        for cli, ser in pairs:\n",
    "            srv_tp_col = df_run[ser + '_tp']\n",
    "            row[ser + '_tp'] = srv_tp_col.mean()\n",
    "            row[ser + '_tp_conf'] = confidence_interval(srv_tp_col)\n",
    "            \n",
    "            cli_rtt_col = df_run_rtt[:, cli]\n",
    "            row[cli + '_rtt'] = cli_rtt_col.mean()\n",
    "            row[cli + '_rtt_conf'] = confidence_interval(cli_rtt_col)\n",
    "\n",
    "        # Add bw and de groups to dfs\n",
    "        for bandwidth, group in zip(bws, ['a', 'b', 'c', 'd']):\n",
    "            b = int(re.sub('[^0-9]', '', bandwidth))\n",
    "            row['bw_' + group] = b\n",
    "        for delay, group in zip(des, ['a', 'b', 'c', 'd']):\n",
    "            d = float(re.sub('[^0-9.]', '', delay))\n",
    "            row['de_' + group] = d\n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# load_iperf_experiments_new('shared_link')\n",
    "# load_single_iperf_experiment_tp('single_bottleneck', 'lia-lia', '10Mbps', '10.0ms')\n",
    "# read_single_iperf_experiment_rtt('two_paths', 'lia', '10Mbps-10Mbps', '10.0ms-10.0ms').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_goodputs_series(folder, filenames):\n",
    "    folder = './logs/{}/{}/{}/{}/'.format(topology, ccs, rates, delays)\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    cli_to_srv = {c: s for c, s in pairs}\n",
    "    \n",
    "    if not os.path.exists(folder) or len(filenames) == 0:\n",
    "        print('Attention, folder {} does not exist or no files are therein!'.format(folder))\n",
    "        \n",
    "    columns = {}\n",
    "    for srv in cli_to_srv.values():\n",
    "        columns[srv + '_tp'] = {}\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(folder):\n",
    "        print(dirpath)\n",
    "        print(filenames[0])\n",
    "        return\n",
    "        client_tuples = [(name,) + extract_rep_host_name(name) for name in filenames]\n",
    "        client_tuples = [t for t in client_tuples if t[0].endswith('iperf.csv') and t[1] in cli_to_srv.keys()]\n",
    "        \n",
    "        # add each client as a tp datapoint\n",
    "        for file_name, host_name, rep in client_tuples:\n",
    "            tp = read_single_iperf_goodput(dirpath, file_name)\n",
    "            srv_name = cli_to_srv[host_name]\n",
    "            columns[srv_name + '_tp'][rep] = tp\n",
    "    df = pd.DataFrame(columns)\n",
    "    df.index.name = 'rep'\n",
    "    if store_info:\n",
    "        df['topology'] = topology\n",
    "        df['ccs'] = ccs\n",
    "        df['bws'] = rates\n",
    "        df['delays'] = delays\n",
    "    return df\n",
    "\n",
    "def load_single_iperf_experiment_tp(topology, ccs, rates, delays, store_info=True):\n",
    "    folder = './logs/{}/{}/{}/{}/'.format(topology, ccs, rates, delays)\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    cli_to_srv = {c: s for c, s in pairs}\n",
    "    \n",
    "    \n",
    "def read_single_iperf_output(folder, host_file, include_info=True):\n",
    "    with open('{}/{}'.format(folder, host_file), 'r') as f:\n",
    "        content = f.read() \\\n",
    "                        .replace('iperf Done.', '') \\\n",
    "                        .replace('[', '') \\\n",
    "                        .replace(']', '') \\\n",
    "                        .replace('iperf3: interrupt - the server has terminated', '') \\\n",
    "                        .strip().splitlines()\n",
    "        \n",
    "        start_i, end_i = 999, 999\n",
    "        for i in range(10):\n",
    "            if content[i].strip().startswith('ID'):\n",
    "                start_i = i + 1\n",
    "            if content[-i].strip().startswith('ID'):\n",
    "                end_i = -(i + 1)\n",
    "                \n",
    "        if start_i > 100 or end_i > 100:\n",
    "            print('Attention, file seems to be of incorrect form: {}/{}'.format(folder, client_file))\n",
    "            \n",
    "        content = content[start_i:end_i]\n",
    "        column_names = ['ID', 'Interval', 'Interval_unit', 'Transfer', 'Transfer_unit',\n",
    "                        'Bandwidth', 'Bandwidth_unit', 'Retr', 'Cwnd', 'Cwnd_unit']\n",
    "        if len(content[0].split()) < 10:\n",
    "            column_names = column_names[:-3]\n",
    "        \n",
    "        df = pd.DataFrame([l.split() for l in content],\n",
    "                          columns=column_names)\n",
    "        name_split = host_file.split('_')\n",
    "        if include_info:\n",
    "            df['repetition'] = name_split[0]\n",
    "            df['host'] = name_split[1]\n",
    "            df['Interval_start'] = df['Interval'].str.split('-').str[0].astype(float)\n",
    "            df['Interval_end'] = df['Interval'].str.split('-').str[1].astype(float)\n",
    "            df['ID'] = pd.to_numeric(df['ID'])\n",
    "            df['Transfer'] = pd.to_numeric(df['Transfer'])\n",
    "            df['Bandwidth'] = pd.to_numeric(df['Bandwidth'])\n",
    "        return df\n",
    "\n",
    "# read_iperf_srv_tp_trace_new('./logs/two_paths/lia/10Mbps-10Mbps/10.0ms-10.0ms/', 'h1', 'h2')\n",
    "# load_single_iperf_experiment_tp_new('two_paths', 'lia', '10Mbps-10Mbps', '10.0ms-10.0ms')\n",
    "# read_iperf_output('./logs/two_paths/lia/10Mbps-10Mbps/10.0ms-10.0ms/', '0-h2_iperf.csv')\n",
    "read_single_iperf_output('./logs/two_paths/lia/10Mbps_10Mbps/30.0ms_30.0ms/', '0_h2_iperf.csv')\n",
    "# read_single_iperf_goodput('./logs/two_paths/lia/10Mbps_10Mbps/10.0ms_10.0ms/', '0_h2_iperf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def init_plots(df, delay_point=30, bw_point=10):\n",
    "    if len([c for c in df.columns if c.startswith('de_')]) > 2:\n",
    "        print('Plotting does not yet support more than two delay groups!')\n",
    "        return\n",
    "    \n",
    "    n_clients = len([c for c in df.columns if c.endswith('_rtt_conf')])\n",
    "    fig = plt.figure(figsize=(9.5, 3.5*n_clients))\n",
    "    \n",
    "    # TODO handle this better, this only takes out part of what should be removed\n",
    "    for column in [c for c in df.columns if c.startswith('bw')]:\n",
    "        df = df[df[column] == bw_point]\n",
    "\n",
    "    for i in range(n_clients):\n",
    "        ax1 = fig.add_subplot(n_clients, 2, 2*i+1)\n",
    "        ax2 = fig.add_subplot(n_clients, 2, 2*i+2)\n",
    "        cli = 'h{}'.format(i*2+1)\n",
    "        serv = 'h{}'.format(i*2+2)\n",
    "        \n",
    "        for cc in df['cc'].unique():\n",
    "            tmp = df[df['cc'] == cc]\n",
    "            if 'de_b' in tmp.columns:\n",
    "                tmp = tmp[tmp['de_b'] == delay_point]\n",
    "            \n",
    "            tmp = tmp.sort_values('de_a')\n",
    "\n",
    "            a1 = tmp.plot(x='de_a', y='{}_tp'.format(serv), yerr='{}_tp_conf'.format(serv), label=cc,\n",
    "                          ax=ax1, grid=True) #, ylim=(0,22))\n",
    "            a2 = tmp.plot(x='de_a', y='{}_rtt'.format(cli), yerr='{}_rtt_conf'.format(cli), label=cc,\n",
    "                          ax=ax2, grid=True) #, ylim=(0,130))\n",
    "\n",
    "        ax1.set_title('Iperf Throughput on {}'.format(serv))\n",
    "        ax1.set_ylabel('Mbps Throughput')\n",
    "        ax1.set_xlabel('ms delay of (second) link')\n",
    "        ax1.autoscale(True, axis='x')\n",
    "\n",
    "        ax2.set_title('Iperf Packet RTT on {}'.format(cli))\n",
    "        ax2.set_ylabel('ms')\n",
    "        ax2.set_xlabel('ms delay of (second) link')\n",
    "        ax2.autoscale(True, axis='x')\n",
    "\n",
    "        if 'de_b' in df.columns:\n",
    "            ax1.axvline(delay_point, color='black', ls=':')\n",
    "            ax2.axvline(delay_point, color='black', ls=':')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "        \n",
    "\n",
    "def de_3d_plot(df):\n",
    "    fig = plt.figure(figsize=(9.5, 9.5))\n",
    "    for i, cc in enumerate(df['cc'].unique()):\n",
    "        ax = fig.add_subplot(3, 2, i+1, projection='3d')\n",
    "        ax.set_title('Throughput for {}'.format(cc))\n",
    "        ax.set_xlabel('ms delay group a')\n",
    "        ax.set_ylabel('ms delay group b')\n",
    "\n",
    "        tmp = df[df['cc'] == cc]\n",
    "        tmp = tmp[(tmp['bw_a'] == 10) & (tmp['bw_b'] == 10)]\n",
    "        ax.plot_trisurf(tmp['de_a'], tmp['de_b'], tmp['h2_tp'], cmap='viridis');\n",
    "        ax.set_zlim(0, 25)\n",
    "        ax.view_init(25, 25)\n",
    "    plt.tight_layout()\n",
    "        \n",
    "def tp_3d_plot(df):\n",
    "    for cc in df['cc'].unique():\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_title('Throughput for {}'.format(cc))\n",
    "        ax.set_xlabel('ms delay group a')\n",
    "        ax.set_ylabel('ms delay group b')\n",
    "\n",
    "        tmp = df[df['cc'] == cc]\n",
    "        tmp = tmp[(tmp['bw_a'] == 10) & (tmp['bw_b'] == 10)]\n",
    "        ax.plot_trisurf(tmp['de_a'], tmp['de_b'], tmp['h2_tp'], cmap='viridis');\n",
    "        ax.view_init(25, 25)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "# init_plots(two_paths_df)\n",
    "# de_3d_plot(two_paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_rtt_timeline_per_cc(topo, bw_dir, de_dir, client='h1', smoothing=3):\n",
    "    fig = plt.figure(figsize=(9.5, 9.5))\n",
    "    subplots = []\n",
    "    max_y = 0\n",
    "    num_lines = 0\n",
    "    for i, cc in enumerate(cc_algorithms):\n",
    "        cc = '_'.join([cc] * num_clients(topo))\n",
    "        ax = fig.add_subplot(3, 2, i+1)\n",
    "        subplots.append(ax)\n",
    "        df = read_single_iperf_experiment_rtt(topo, cc, bw_dir, de_dir)\n",
    "        df = df[df['tcp.analysis.ack_rtt'] > 0.06].sort_values('frame.time_relative')\n",
    "        max_y = max(max_y, df['tcp.analysis.ack_rtt'].max())\n",
    "        \n",
    "        for key, grp in df.groupby(['repetition', 'tcp.stream']):\n",
    "            num_lines += 1\n",
    "            if smoothing > 1:\n",
    "                ax.plot(grp['frame.time_relative'], grp['tcp.analysis.ack_rtt'].rolling(window=smoothing).mean(),\n",
    "                        label='rep/stream {}'.format(key))\n",
    "            else:\n",
    "                sub = grp.plot(ax=ax, style='+', x='frame.time_relative', y='tcp.analysis.ack_rtt',\n",
    "                               label='rep/stream {}'.format(key))\n",
    "            \n",
    "        ax.set_title('{}: RTT Timeline on Host {}'.format(cc, client))\n",
    "        ax.set_ylabel('ms RTT')\n",
    "        ax.set_xlabel('s Experiment Time')\n",
    "        ax.autoscale(True)\n",
    "        ax.grid()\n",
    "        ax.legend()\n",
    "        if num_lines > 6:\n",
    "            ax.legend().remove()\n",
    "    \n",
    "    for ax in subplots:\n",
    "        ax.set_ylim(0, max_y)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def autolabel(rects, ax):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for i, rect in enumerate(rects):\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.2f}'.format(height), xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3 + i*2),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\", ha='center', va='bottom', rotation=90)\n",
    "        \n",
    "def plot_tp_timeline_per_cc(topo, bw_dir, de_dir, servers=['h2'], repetitions=3, smoothing=1, y_max=35):\n",
    "    fig = plt.figure(figsize=(9.5, 9.5*len(servers)))\n",
    "    for i, cc in enumerate(cc_algorithms):\n",
    "        cc = '_'.join([cc] * num_clients(topo))\n",
    "        for j, serv in enumerate(servers):\n",
    "            ax = fig.add_subplot(3*len(servers), 2, len(servers)*i+j+1)\n",
    "            folder = './logs/{}/{}/{}/{}'.format(topo, cc, bw_dir, de_dir)\n",
    "            df = read_iperf_srv_tp_trace(folder, client='h1', server=serv, repetitions=repetitions)\n",
    "\n",
    "            for key, grp in df.groupby(['repetition']):\n",
    "                width = grp['Interval_start'].max() / 25\n",
    "                if smoothing > 1:\n",
    "                    ax.plot(grp['Interval_start'], grp['Bandwidth'].rolling(window=smoothing).mean(),\n",
    "                            label='rep {}'.format(key))\n",
    "                else:\n",
    "                    grp.plot(ax=ax, x='Interval_start', y='Bandwidth', style='+', label='rep {}'.format(key))\n",
    "                b = ax.bar(grp['Interval_start'].max()+(key+1)*width+5, grp['Bandwidth'].mean(), width=width)\n",
    "                ax.autoscale(True)\n",
    "                autolabel(b, ax)\n",
    "\n",
    "            ax.title.set_text('{}: Throughput Timeline on Host {}'.format(cc, serv))\n",
    "            ax.set_ylabel('Mbps Throughput')\n",
    "            ax.set_xlabel('s Experiment Time')\n",
    "            ax.set_ylim((0, y_max))\n",
    "            ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "# plot_rtt_timeline_per_cc('shared_link', '15Mbps', '10ms')\n",
    "# plot_tp_timeline_per_cc('shared_link', '15Mbps', '10ms', smoothing=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_paths_df = load_iperf_experiments_new('two_paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_paths_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_paths_df.drop(['bw_a', 'bw_b', 'de_a', 'de_b'], axis=1).groupby('cc').describe()\n",
    "two_paths_df.groupby('cc')['h2_tp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_plots(two_paths_df, 30)\n",
    "# init_plots(two_paths_df, 90)\n",
    "de_3d_plot(two_paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rtt_timeline_per_cc('two_paths', '10Mbps_10Mbps', '30.0ms_30.0ms', 'h1', smoothing=10)\n",
    "plot_tp_timeline_per_cc('two_paths', '10Mbps_10Mbps', '30.0ms_30.0ms', ['h2'], 3, smoothing=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 9.5))\n",
    "big_df = pd.DataFrame()\n",
    "\n",
    "for i, cc in enumerate(cc_algorithms):\n",
    "    df = load_single_iperf_experiment_tp('two_paths', cc, '10Mbps_10Mbps', '30.0ms_30.0ms')\n",
    "    df['bw'] = 20\n",
    "    df['de'] = 10\n",
    "    df['lost tp'] = (df['bw'] - df['h2_tp'])\n",
    "    big_df = big_df.append(df, ignore_index=True)\n",
    "    \n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    df['lost tp'].hist(ax=ax, cumulative=True, density=1, bins=50)\n",
    "    ax.title.set_text('{}: CDF wasted bw'.format(cc))\n",
    "    ax.set_ylabel('CDF')\n",
    "    ax.set_xlabel('absolute bw wasted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "big_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_link_df = load_iperf_experiments_new('shared_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('BW: ', shared_link_df['bw_a'].unique())\n",
    "print('De: ', shared_link_df['de_a'].unique())\n",
    "# shared_link_df = shared_link_df.drop_duplicates(subset=['bw_a', 'cc', 'de_a'])\n",
    "shared_link_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp_shared_link_df = shared_link_df # shared_link_df[shared_link_df['de_a'] != 10]\n",
    "init_plots(tmp_shared_link_df)\n",
    "# de_3d_plot(shared_link_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# weird results for 0ms/30ms\n",
    "bw, de = '10Mbps', '30.0ms'\n",
    "plot_rtt_timeline_per_cc('shared_link', bw, de, 'h1', 1)\n",
    "plot_tp_timeline_per_cc('shared_link', bw, de, ['h2', 'h4'], 3, smoothing=5, y_max=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 9.5))\n",
    "dfs = {}\n",
    "\n",
    "for i, cc in enumerate(cc_algorithms):\n",
    "    ccs = '_'.join([cc]*2)\n",
    "    df = load_single_iperf_experiment_tp('shared_link', ccs, '10Mbps', '30.0ms')\n",
    "    df['bw'] = 10\n",
    "    df['de'] = 10\n",
    "    df['lost tp'] = (df['bw'] - df['h2_tp'] - df['h4_tp']) / df['bw']\n",
    "    df['tp_diff'] = (df['h2_tp'] - df['h4_tp']).abs()\n",
    "\n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    df['lost tp'].hist(ax=ax, cumulative=True, density=1, bins=50)\n",
    "    ax.title.set_text('{}: CDF wasted bw'.format(cc))\n",
    "    ax.set_ylabel('CDF')\n",
    "    ax.set_xlabel('absolute bw wasted')\n",
    "    dfs[cc] = df\n",
    "plt.tight_layout()\n",
    "dfs['wvegas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MP vs SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_vs_sp_df = load_iperf_experiments_new('mp_vs_sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_vs_sp_df['h2_tp_on_b'] = mp_vs_sp_df['h2_tp'] - mp_vs_sp_df['bw_a']\n",
    "# mp_vs_sp_df[['cc', 'bw_a', 'bw_b', 'h2_tp_on_b']]\n",
    "mp_vs_sp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 9.5))\n",
    "cur_df = mp_vs_sp_df[mp_vs_sp_df['bw_a'] == 15]\n",
    "cur_df['x'] = cur_df['bw_a']/cur_df['bw_b']\n",
    "cur_df = cur_df.sort_values('x')\n",
    "\n",
    "for i, cc in enumerate(mp_vs_sp_df['cc'].unique()):\n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    tmp = cur_df[cur_df['cc'] == cc]\n",
    "    \n",
    "    ax.plot(tmp['x'], tmp['h2_tp'], label='h2 (mp)')\n",
    "    ax.plot(tmp['x'], tmp['h4_tp'], label='h4 (sp)')\n",
    "    ax.plot(tmp['x'], tmp['bw_b'], label='bw_b', linestyle='dashed', c='orange')\n",
    "    ax.plot(tmp['x'], tmp['bw_a'], label='bw_a', linestyle='dashed', c='blue')\n",
    "    ax.set_title('{}'.format(cc))\n",
    "    ax.set_xlabel('bw_a / bw_b')\n",
    "    ax.set_ylabel('Mbps Throughput')\n",
    "    ax.set_ylim((0, cur_df['bw_b'].max()+1))\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 9.5))\n",
    "cur_df = mp_vs_sp_df[mp_vs_sp_df['bw_a'] == 15]\n",
    "cur_df['x'] = cur_df['bw_a']/cur_df['bw_b']\n",
    "cur_df['fair_allocation'] = cur_df[['bw_a', 'bw_b']].apply(lambda x: x[0] if x[0]>x[1] else (x[0]+x[1])/2, axis=1)\n",
    "cur_df = cur_df.sort_values('x')\n",
    "\n",
    "for i, cc in enumerate(mp_vs_sp_df['cc'].unique()):\n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    tmp = cur_df[cur_df['cc'] == cc]\n",
    "    \n",
    "    ax.plot(tmp['x'], tmp['h2_tp'] / tmp['bw_a'], label='h2 (mp)')\n",
    "    ax.plot(tmp['x'], tmp['h4_tp'] / tmp['bw_b'], label='h4 (sp)')\n",
    "    ax.plot(tmp['x'], tmp['fair_allocation'] / tmp['bw_a'], label='fair alloc', linestyle=':')\n",
    "    #ax.plot(tmp['x'], tmp['bw_b'], label='bw_b', linestyle='dashed')\n",
    "    #ax.plot(tmp['x'], tmp['bw_a'], label='bw_a', linestyle='dashed')\n",
    "    ax.set_title('{}'.format(cc))\n",
    "    ax.set_xlabel('bw_a / bw_b')\n",
    "    ax.set_ylabel('Throughput normalized')\n",
    "    ax.set_ylim((0.5, 1.5))\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "# cur_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Single Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_bottleneck_df = load_iperf_experiments_new('single_bottleneck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_bottleneck_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_plots(single_bottleneck_df)\n",
    "# de_3d_plot(single_bottleneck_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymetric MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asym_mp_df = load_iperf_experiments_new('asym_mp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asym_mp_df['total_bw'] = 15\n",
    "asym_mp_df['wasted_bw'] = asym_mp_df['total_bw'] - asym_mp_df['h2_tp'] - asym_mp_df['h4_tp'] - asym_mp_df['h6_tp']\n",
    "asym_mp_df.drop(['bw_a', 'bw_b', 'de_a', 'de_b'], axis=1).set_index('cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = asym_mp_df.copy()\n",
    "for h in ['h2', 'h4', 'h6']:\n",
    "    df['diff_to_fair_' + h] = df[h + '_tp'] - 5\n",
    "# asym_mp_df\n",
    "df = df.drop([c for c in asym_mp_df.columns if\n",
    "              not ('tp' in c or 'cc' in c or 'wasted' in c)], axis=1)\n",
    "\n",
    "\n",
    "# Plot bandwidth allocation per flow\n",
    "yerr = df.set_index('cc')[['h2_tp_conf', 'h4_tp_conf', 'h6_tp_conf']]\n",
    "ax = df.set_index('cc')[['h2_tp', 'h4_tp', 'h6_tp']].plot.barh(stacked=True)\n",
    "ax.axvline(5)\n",
    "ax.axvline(10)\n",
    "ax.axvline(15)\n",
    "\n",
    "ax.set_title('Throughput per Flow')\n",
    "ax.set_xlabel('Mbps')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlim((0, 15.5))\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
