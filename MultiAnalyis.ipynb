{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import subprocess\n",
    "import json\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "cc_algorithms = ['lia', 'olia', 'balia', 'wvegas', 'cubic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_all():\n",
    "    folder = './logs/'\n",
    "    for _ in range(8):\n",
    "        for dirpath, dirnames, filenames in os.walk(folder):\n",
    "            for d in filenames + dirnames:\n",
    "                if '-' in d:\n",
    "                    full_path = '{}/{}'.format(dirpath, d)\n",
    "                    os.rename(full_path, full_path.replace('-', '_'))\n",
    "rename_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON config files\n",
    "def load_config(topology):\n",
    "    file_name = './topologies/{}.json'.format(topology)\n",
    "    if not os.path.isfile(file_name):\n",
    "        print('JSON topology file not found! {}'.format(file_name))\n",
    "        return None\n",
    "\n",
    "    with open(file_name, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_iperf_pairings(topology):\n",
    "    config = load_config(topology)\n",
    "    pairs = []\n",
    "    for node in [node for node in config['nodes'] if node['id'].startswith('h')]:\n",
    "        if 'server' in node['properties']:\n",
    "            pairs.append((str(node['id']), str(node['properties']['server'])))\n",
    "\n",
    "    # make sure every host is included in some connection\n",
    "    hosts = itertools.chain.from_iterable(pairs)\n",
    "    for node in [node for node in config['nodes'] if node['id'].startswith('h')]:\n",
    "        if node['id'] not in hosts:\n",
    "            print('Host {} not contained in any host pairings!'.format(node))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def num_clients(topology):\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    return len(pairs)\n",
    "\n",
    "\n",
    "def confidence_interval(series, z=1.96):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval for a given series. Default is 95% confidence interval.\n",
    "    See https://en.wikipedia.org/wiki/Confidence_interval#Basic_steps for further values.\n",
    "    \"\"\"\n",
    "    stats = series.agg(['mean', 'count', 'std'])\n",
    "    return z*stats['std']/math.sqrt(stats['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO simplify and use in upper function to eliminate duplicat code\n",
    "def read_iperf_srv_tp_trace(folder, client, server, repetitions):\n",
    "    file_name = folder + '/{}_{}_iperf.csv'\n",
    "    \n",
    "    tp_dfs = pd.DataFrame()\n",
    "    for rep in range(repetitions):\n",
    "        ser_file = file_name.format(rep, server)\n",
    "            \n",
    "        with open(ser_file, 'r') as f:\n",
    "            content = f.read().replace('iperf3: interrupt - the server has terminated', '').strip().splitlines()\n",
    "            content = content[6:-4] # TODO replace with conditional cutting\n",
    "            df = pd.DataFrame([l.replace('[', '').replace(']','').split() for l in content],\n",
    "                             columns=['ID', 'Interval', 'Interval_unit', 'Transfer', 'Transfer_unit', 'Bandwidth', 'Bandwidth_unit'])\n",
    "            df['repetition'] = rep\n",
    "            tp_dfs = tp_dfs.append(df, ignore_index=True)\n",
    "            \n",
    "    tp_dfs['client'] = client\n",
    "    tp_dfs['server'] = server\n",
    "    tp_dfs['Interval_start'] = tp_dfs['Interval'].str.split('-').str[0].astype(float)\n",
    "    tp_dfs['Interval_end'] = tp_dfs['Interval'].str.split('-').str[1].astype(float)\n",
    "    tp_dfs['ID'] = pd.to_numeric(tp_dfs['ID'])\n",
    "    tp_dfs['Transfer'] = pd.to_numeric(tp_dfs['Transfer'])\n",
    "    tp_dfs['Bandwidth'] = pd.to_numeric(tp_dfs['Bandwidth'])\n",
    "    return tp_dfs\n",
    "\n",
    "    \n",
    "def read_pcap_csv(file_name):\n",
    "    df = pd.read_csv(file_name, delimiter='\\t')\n",
    "    # Note: puts rtt into [ms] instead of [s]\n",
    "    df['tcp.analysis.ack_rtt'] = df['tcp.analysis.ack_rtt'] * 1000\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_single_iperf_experiment_rtt(topology, ccs, rates, delays, store_info=True):\n",
    "    folder = './logs/{}/{}/{}/{}/'.format(topology, ccs, rates, delays)\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    cli_to_srv = {c: s for c, s in pairs}\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    if not os.path.exists(folder):\n",
    "        print('Attention, folder {} does not exist!'.format(folder))\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(folder):\n",
    "        client_tuples = [(name,) + extract_rep_host_name(name) for name in filenames]\n",
    "        client_tuples = [t for t in client_tuples if t[0].endswith('iperf_dump.csv')]\n",
    "        \n",
    "        # add each client as a rtt datapoint\n",
    "        for file_name, host_name, rep in client_tuples:\n",
    "            pcap = read_pcap_csv('{}/{}'.format(dirpath, file_name))\n",
    "            pcap['repetition'] = rep\n",
    "            pcap['host'] = host_name\n",
    "            df = df.append(pcap, ignore_index=True)\n",
    "            \n",
    "    df = df.dropna(subset=['tcp.analysis.ack_rtt'])\n",
    "    if store_info:\n",
    "        df['topology'] = topology\n",
    "        df['ccs'] = ccs\n",
    "        df['bw'] = rates\n",
    "        df['delays'] = delays\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_rep_host_name(filename):\n",
    "    \"\"\" Returns a tuple (host_name, rep) \"\"\"\n",
    "    rep_hname = filename.split('_')\n",
    "    return rep_hname[1], int(rep_hname[0])\n",
    "\n",
    "\n",
    "def read_single_iperf_goodput(folder, client_file):\n",
    "    with open('{}/{}'.format(folder, client_file), 'r') as f:\n",
    "        content = f.read()[-300:] \\\n",
    "                    .replace('iperf Done.', '') \\\n",
    "                    .replace('iperf3: interrupt - the server has terminated', '') \\\n",
    "                    .strip().splitlines()\n",
    "        recv_line = content[-1].split()\n",
    "        assert 'receiver' in recv_line\n",
    "        return float(recv_line[6])\n",
    "\n",
    "\n",
    "def load_single_iperf_experiment_tp(topology, ccs, rates, delays, store_info=True):\n",
    "    folder = './logs/{}/{}/{}/{}/'.format(topology, ccs, rates, delays)\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    cli_to_srv = {c: s for c, s in pairs}\n",
    "    \n",
    "    if not os.path.exists(folder):\n",
    "        print('Attention, folder {} does not exist!'.format(folder))\n",
    "        \n",
    "    columns = {}\n",
    "    for srv in cli_to_srv.values():\n",
    "        columns[srv + '_tp'] = {}\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(folder):\n",
    "        client_tuples = [(name,) + extract_rep_host_name(name) for name in filenames]\n",
    "        client_tuples = [t for t in client_tuples if t[0].endswith('iperf.csv') and t[1] in cli_to_srv.keys()]\n",
    "        \n",
    "        # add each client as a tp datapoint\n",
    "        for file_name, host_name, rep in client_tuples:\n",
    "            tp = read_single_iperf_goodput(dirpath, file_name)\n",
    "            srv_name = cli_to_srv[host_name]\n",
    "            columns[srv_name + '_tp'][rep] = tp\n",
    "    df = pd.DataFrame(columns)\n",
    "    df.index.name = 'rep'\n",
    "    if store_info:\n",
    "        df['topology'] = topology\n",
    "        df['ccs'] = ccs\n",
    "        df['bws'] = rates\n",
    "        df['delays'] = delays\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_iperf_experiments_new(topology, repetitions=3):\n",
    "    \"\"\"\n",
    "    Read in log data from experiments, every throughput should come out in [Mbps] and times in [ms].\n",
    "    One exception to this rule is the relative time since experiment start in the rtt trace.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk('./logs/{}'.format(topology)):\n",
    "        if dirnames:\n",
    "            continue\n",
    "        \n",
    "        # Leaf folder, read in files and analyze\n",
    "        # dirpath has form \"./logs/two_paths/cubic/25Mbps-9Mbps/10ms-10ms\"\n",
    "        dirpath_split = dirpath.split('/') # ['.', 'logs', 'two_paths', 'lia', '9Mbps-13Mbps', '10ms-10ms']\n",
    "        cc_name = dirpath_split[-3]\n",
    "        cc = cc_name\n",
    "        bw_name = dirpath_split[-2]\n",
    "        bws = bw_name.split('_')\n",
    "        de_name = dirpath_split[-1]\n",
    "        des = de_name.split('_')\n",
    "        \n",
    "        df_run = load_single_iperf_experiment_tp(topology, cc_name, bw_name, de_name, store_info=False)\n",
    "        df_run_rtt = read_single_iperf_experiment_rtt(topology, cc_name, bw_name, de_name, store_info=False)\n",
    "        \n",
    "        df_run_rtt = df_run_rtt.groupby(['repetition', 'host'])['tcp.analysis.ack_rtt'].mean()\n",
    "\n",
    "        # read in data for pairings\n",
    "        row = {'cc': cc}\n",
    "        for cli, ser in pairs:\n",
    "            srv_tp_col = df_run[ser + '_tp']\n",
    "            row[ser + '_tp'] = srv_tp_col.mean()\n",
    "            row[ser + '_tp_conf'] = confidence_interval(srv_tp_col)\n",
    "            \n",
    "            cli_rtt_col = df_run_rtt[:, cli]\n",
    "            row[cli + '_rtt'] = cli_rtt_col.mean()\n",
    "            row[cli + '_rtt_conf'] = confidence_interval(cli_rtt_col)\n",
    "\n",
    "        # Add bw and de groups to dfs\n",
    "        for bandwidth, group in zip(bws, ['a', 'b', 'c', 'd']):\n",
    "            b = int(re.sub('[^0-9]', '', bandwidth))\n",
    "            row['bw_' + group] = b\n",
    "        for delay, group in zip(des, ['a', 'b', 'c', 'd']):\n",
    "            d = float(re.sub('[^0-9.]', '', delay))\n",
    "            row['de_' + group] = d\n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# load_iperf_experiments_new('shared_link')\n",
    "# load_single_iperf_experiment_tp('single_bottleneck', 'lia-lia', '10Mbps', '10.0ms')\n",
    "# read_single_iperf_experiment_rtt('two_paths', 'lia', '10Mbps-10Mbps', '10.0ms-10.0ms').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_goodputs_series(folder, filenames):\n",
    "    folder = './logs/{}/{}/{}/{}/'.format(topology, ccs, rates, delays)\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    cli_to_srv = {c: s for c, s in pairs}\n",
    "    \n",
    "    if not os.path.exists(folder) or len(filenames) == 0:\n",
    "        print('Attention, folder {} does not exist or no files are therein!'.format(folder))\n",
    "        \n",
    "    columns = {}\n",
    "    for srv in cli_to_srv.values():\n",
    "        columns[srv + '_tp'] = {}\n",
    "    \n",
    "    for dirpath, dirnames, filenames in os.walk(folder):\n",
    "        print(dirpath)\n",
    "        print(filenames[0])\n",
    "        return\n",
    "        client_tuples = [(name,) + extract_rep_host_name(name) for name in filenames]\n",
    "        client_tuples = [t for t in client_tuples if t[0].endswith('iperf.csv') and t[1] in cli_to_srv.keys()]\n",
    "        \n",
    "        # add each client as a tp datapoint\n",
    "        for file_name, host_name, rep in client_tuples:\n",
    "            tp = read_single_iperf_goodput(dirpath, file_name)\n",
    "            srv_name = cli_to_srv[host_name]\n",
    "            columns[srv_name + '_tp'][rep] = tp\n",
    "    df = pd.DataFrame(columns)\n",
    "    df.index.name = 'rep'\n",
    "    if store_info:\n",
    "        df['topology'] = topology\n",
    "        df['ccs'] = ccs\n",
    "        df['bws'] = rates\n",
    "        df['delays'] = delays\n",
    "    return df\n",
    "\n",
    "def load_single_iperf_experiment_tp(topology, ccs, rates, delays, store_info=True):\n",
    "    folder = './logs/{}/{}/{}/{}/'.format(topology, ccs, rates, delays)\n",
    "    pairs = get_iperf_pairings(topology)\n",
    "    cli_to_srv = {c: s for c, s in pairs}\n",
    "    \n",
    "    \n",
    "def read_single_iperf_output(folder, host_file, include_info=True):\n",
    "    with open('{}/{}'.format(folder, host_file), 'r') as f:\n",
    "        content = f.read() \\\n",
    "                        .replace('iperf Done.', '') \\\n",
    "                        .replace('[', '') \\\n",
    "                        .replace(']', '') \\\n",
    "                        .replace('iperf3: interrupt - the server has terminated', '') \\\n",
    "                        .strip().splitlines()\n",
    "        \n",
    "        start_i, end_i = 999, 999\n",
    "        for i in range(10):\n",
    "            if content[i].strip().startswith('ID'):\n",
    "                start_i = i + 1\n",
    "            if content[-i].strip().startswith('ID'):\n",
    "                end_i = -(i + 1)\n",
    "                \n",
    "        if start_i > 100 or end_i > 100:\n",
    "            print('Attention, file seems to be of incorrect form: {}/{}'.format(folder, client_file))\n",
    "            \n",
    "        content = content[start_i:end_i]\n",
    "        column_names = ['ID', 'Interval', 'Interval_unit', 'Transfer', 'Transfer_unit',\n",
    "                        'Bandwidth', 'Bandwidth_unit', 'Retr', 'Cwnd', 'Cwnd_unit']\n",
    "        if len(content[0].split()) < 10:\n",
    "            column_names = column_names[:-3]\n",
    "        \n",
    "        df = pd.DataFrame([l.split() for l in content],\n",
    "                          columns=column_names)\n",
    "        name_split = host_file.split('_')\n",
    "        if include_info:\n",
    "            df['repetition'] = name_split[0]\n",
    "            df['host'] = name_split[1]\n",
    "            df['Interval_start'] = df['Interval'].str.split('-').str[0].astype(float)\n",
    "            df['Interval_end'] = df['Interval'].str.split('-').str[1].astype(float)\n",
    "            df['ID'] = pd.to_numeric(df['ID'])\n",
    "            df['Transfer'] = pd.to_numeric(df['Transfer'])\n",
    "            df['Bandwidth'] = pd.to_numeric(df['Bandwidth'])\n",
    "        return df\n",
    "\n",
    "# read_iperf_srv_tp_trace_new('./logs/two_paths/lia/10Mbps-10Mbps/10.0ms-10.0ms/', 'h1', 'h2')\n",
    "# load_single_iperf_experiment_tp_new('two_paths', 'lia', '10Mbps-10Mbps', '10.0ms-10.0ms')\n",
    "# read_iperf_output('./logs/two_paths/lia/10Mbps-10Mbps/10.0ms-10.0ms/', '0-h2_iperf.csv')\n",
    "read_single_iperf_output('./logs/two_paths/lia/10Mbps_10Mbps/30.0ms_30.0ms/', '0_h2_iperf.csv')\n",
    "# read_single_iperf_goodput('./logs/two_paths/lia/10Mbps_10Mbps/10.0ms_10.0ms/', '0_h2_iperf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def init_plots(df, delay_point=30, bw_point=10):\n",
    "    if len([c for c in df.columns if c.startswith('de_')]) > 2:\n",
    "        print('Plotting does not yet support more than two delay groups!')\n",
    "        return\n",
    "    \n",
    "    n_clients = len([c for c in df.columns if c.endswith('_rtt_conf')])\n",
    "    fig = plt.figure(figsize=(9.5, 3.5*n_clients))\n",
    "    \n",
    "    # TODO handle this better, this only takes out part of what should be removed\n",
    "    for column in [c for c in df.columns if c.startswith('bw')]:\n",
    "        df = df[df[column] == bw_point]\n",
    "\n",
    "    for i in range(n_clients):\n",
    "        ax1 = fig.add_subplot(n_clients, 2, 2*i+1)\n",
    "        ax2 = fig.add_subplot(n_clients, 2, 2*i+2)\n",
    "        cli = 'h{}'.format(i*2+1)\n",
    "        serv = 'h{}'.format(i*2+2)\n",
    "        \n",
    "        for cc in df['cc'].unique():\n",
    "            tmp = df[df['cc'] == cc]\n",
    "            if 'de_b' in tmp.columns:\n",
    "                tmp = tmp[tmp['de_b'] == delay_point]\n",
    "            \n",
    "            tmp = tmp.sort_values('de_a')\n",
    "\n",
    "            a1 = tmp.plot(x='de_a', y='{}_tp'.format(serv), yerr='{}_tp_conf'.format(serv), label=cc,\n",
    "                          ax=ax1, grid=True) #, ylim=(0,22))\n",
    "            a2 = tmp.plot(x='de_a', y='{}_rtt'.format(cli), yerr='{}_rtt_conf'.format(cli), label=cc,\n",
    "                          ax=ax2, grid=True) #, ylim=(0,130))\n",
    "\n",
    "        ax1.set_title('Iperf Throughput on {}'.format(serv))\n",
    "        ax1.set_ylabel('Mbps Throughput')\n",
    "        ax1.set_xlabel('ms delay of (second) link')\n",
    "        ax1.autoscale(True, axis='x')\n",
    "\n",
    "        ax2.set_title('Iperf Packet RTT on {}'.format(cli))\n",
    "        ax2.set_ylabel('ms')\n",
    "        ax2.set_xlabel('ms delay of (second) link')\n",
    "        ax2.autoscale(True, axis='x')\n",
    "\n",
    "        if 'de_b' in df.columns:\n",
    "            ax1.axvline(delay_point, color='black', ls=':')\n",
    "            ax2.axvline(delay_point, color='black', ls=':')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "        \n",
    "\n",
    "def de_3d_plot(df):\n",
    "    fig = plt.figure(figsize=(9.5, 9.5))\n",
    "    for i, cc in enumerate(df['cc'].unique()):\n",
    "        ax = fig.add_subplot(3, 2, i+1, projection='3d')\n",
    "        ax.set_title('Throughput for {}'.format(cc))\n",
    "        ax.set_xlabel('ms delay group a')\n",
    "        ax.set_ylabel('ms delay group b')\n",
    "\n",
    "        tmp = df[df['cc'] == cc]\n",
    "        tmp = tmp[(tmp['bw_a'] == 10) & (tmp['bw_b'] == 10)]\n",
    "        ax.plot_trisurf(tmp['de_a'], tmp['de_b'], tmp['h2_tp'], cmap='viridis');\n",
    "        ax.set_zlim(0, 25)\n",
    "        ax.view_init(25, 25)\n",
    "    plt.tight_layout()\n",
    "        \n",
    "def tp_3d_plot(df):\n",
    "    for cc in df['cc'].unique():\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.set_title('Throughput for {}'.format(cc))\n",
    "        ax.set_xlabel('ms delay group a')\n",
    "        ax.set_ylabel('ms delay group b')\n",
    "\n",
    "        tmp = df[df['cc'] == cc]\n",
    "        tmp = tmp[(tmp['bw_a'] == 10) & (tmp['bw_b'] == 10)]\n",
    "        ax.plot_trisurf(tmp['de_a'], tmp['de_b'], tmp['h2_tp'], cmap='viridis');\n",
    "        ax.view_init(25, 25)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "# init_plots(two_paths_df)\n",
    "# de_3d_plot(two_paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_rtt_timeline_per_cc(topo, bw_dir, de_dir, client='h1', smoothing=3):\n",
    "    fig = plt.figure(figsize=(9.5, 9.5))\n",
    "    subplots = []\n",
    "    max_y = 0\n",
    "    num_lines = 0\n",
    "    for i, cc in enumerate(cc_algorithms):\n",
    "        cc = '_'.join([cc] * num_clients(topo))\n",
    "        ax = fig.add_subplot(3, 2, i+1)\n",
    "        subplots.append(ax)\n",
    "        df = read_single_iperf_experiment_rtt(topo, cc, bw_dir, de_dir)\n",
    "        df = df[df['tcp.analysis.ack_rtt'] > 0.06].sort_values('frame.time_relative')\n",
    "        max_y = max(max_y, df['tcp.analysis.ack_rtt'].max())\n",
    "        \n",
    "        for key, grp in df.groupby(['repetition', 'tcp.stream']):\n",
    "            num_lines += 1\n",
    "            if smoothing > 1:\n",
    "                ax.plot(grp['frame.time_relative'], grp['tcp.analysis.ack_rtt'].rolling(window=smoothing).mean(),\n",
    "                        label='rep/stream {}'.format(key))\n",
    "            else:\n",
    "                sub = grp.plot(ax=ax, style='+', x='frame.time_relative', y='tcp.analysis.ack_rtt',\n",
    "                               label='rep/stream {}'.format(key))\n",
    "            \n",
    "        ax.set_title('{}: RTT Timeline on Host {}'.format(cc, client))\n",
    "        ax.set_ylabel('ms RTT')\n",
    "        ax.set_xlabel('s Experiment Time')\n",
    "        ax.autoscale(True)\n",
    "        ax.grid()\n",
    "        ax.legend()\n",
    "        if num_lines > 6:\n",
    "            ax.legend().remove()\n",
    "    \n",
    "    for ax in subplots:\n",
    "        ax.set_ylim(0, max_y)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def autolabel(rects, ax):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for i, rect in enumerate(rects):\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.2f}'.format(height), xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3 + i*2),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\", ha='center', va='bottom', rotation=90)\n",
    "        \n",
    "def plot_tp_timeline_per_cc(topo, bw_dir, de_dir, servers=['h2'], repetitions=3, smoothing=1, y_max=35):\n",
    "    fig = plt.figure(figsize=(9.5, 9.5*len(servers)))\n",
    "    for i, cc in enumerate(cc_algorithms):\n",
    "        cc = '_'.join([cc] * num_clients(topo))\n",
    "        for j, serv in enumerate(servers):\n",
    "            ax = fig.add_subplot(3*len(servers), 2, len(servers)*i+j+1)\n",
    "            folder = './logs/{}/{}/{}/{}'.format(topo, cc, bw_dir, de_dir)\n",
    "            df = read_iperf_srv_tp_trace(folder, client='h1', server=serv, repetitions=repetitions)\n",
    "\n",
    "            for key, grp in df.groupby(['repetition']):\n",
    "                width = grp['Interval_start'].max() / 25\n",
    "                if smoothing > 1:\n",
    "                    ax.plot(grp['Interval_start'], grp['Bandwidth'].rolling(window=smoothing).mean(),\n",
    "                            label='rep {}'.format(key))\n",
    "                else:\n",
    "                    grp.plot(ax=ax, x='Interval_start', y='Bandwidth', style='+', label='rep {}'.format(key))\n",
    "                b = ax.bar(grp['Interval_start'].max()+(key+1)*width+5, grp['Bandwidth'].mean(), width=width)\n",
    "                ax.autoscale(True)\n",
    "                autolabel(b, ax)\n",
    "\n",
    "            ax.title.set_text('{}: Throughput Timeline on Host {}'.format(cc, serv))\n",
    "            ax.set_ylabel('Mbps Throughput')\n",
    "            ax.set_xlabel('s Experiment Time')\n",
    "            ax.set_ylim((0, y_max))\n",
    "            ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "# plot_rtt_timeline_per_cc('shared_link', '15Mbps', '10ms')\n",
    "# plot_tp_timeline_per_cc('shared_link', '15Mbps', '10ms', smoothing=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_paths_df = load_iperf_experiments_new('two_paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_paths_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two_paths_df.drop(['bw_a', 'bw_b', 'de_a', 'de_b'], axis=1).groupby('cc').describe()\n",
    "two_paths_df.groupby('cc')['h2_tp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_plots(two_paths_df, 30)\n",
    "# init_plots(two_paths_df, 90)\n",
    "de_3d_plot(two_paths_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rtt_timeline_per_cc('two_paths', '10Mbps_10Mbps', '30.0ms_30.0ms', 'h1', smoothing=10)\n",
    "plot_tp_timeline_per_cc('two_paths', '10Mbps_10Mbps', '30.0ms_30.0ms', ['h2'], 3, smoothing=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 9.5))\n",
    "big_df = pd.DataFrame()\n",
    "\n",
    "for i, cc in enumerate(cc_algorithms):\n",
    "    df = load_single_iperf_experiment_tp('two_paths', cc, '10Mbps_10Mbps', '30.0ms_30.0ms')\n",
    "    df['bw'] = 20\n",
    "    df['de'] = 10\n",
    "    df['lost tp'] = (df['bw'] - df['h2_tp'])\n",
    "    big_df = big_df.append(df, ignore_index=True)\n",
    "    \n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    df['lost tp'].hist(ax=ax, cumulative=True, density=1, bins=50)\n",
    "    ax.title.set_text('{}: CDF wasted bw'.format(cc))\n",
    "    ax.set_ylabel('CDF')\n",
    "    ax.set_xlabel('absolute bw wasted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "big_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_link_df = load_iperf_experiments_new('shared_link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('BW: ', shared_link_df['bw_a'].unique())\n",
    "print('De: ', shared_link_df['de_a'].unique())\n",
    "# shared_link_df = shared_link_df.drop_duplicates(subset=['bw_a', 'cc', 'de_a'])\n",
    "shared_link_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp_shared_link_df = shared_link_df # shared_link_df[shared_link_df['de_a'] != 10]\n",
    "init_plots(tmp_shared_link_df)\n",
    "# de_3d_plot(shared_link_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# weird results for 0ms/30ms\n",
    "bw, de = '10Mbps', '30.0ms'\n",
    "plot_rtt_timeline_per_cc('shared_link', bw, de, 'h1', 1)\n",
    "plot_tp_timeline_per_cc('shared_link', bw, de, ['h2', 'h4'], 3, smoothing=5, y_max=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 9.5))\n",
    "dfs = {}\n",
    "\n",
    "for i, cc in enumerate(cc_algorithms):\n",
    "    ccs = '_'.join([cc]*2)\n",
    "    df = load_single_iperf_experiment_tp('shared_link', ccs, '10Mbps', '30.0ms')\n",
    "    df['bw'] = 10\n",
    "    df['de'] = 10\n",
    "    df['lost tp'] = (df['bw'] - df['h2_tp'] - df['h4_tp']) / df['bw']\n",
    "    df['tp_diff'] = (df['h2_tp'] - df['h4_tp']).abs()\n",
    "\n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    df['lost tp'].hist(ax=ax, cumulative=True, density=1, bins=50)\n",
    "    ax.title.set_text('{}: CDF wasted bw'.format(cc))\n",
    "    ax.set_ylabel('CDF')\n",
    "    ax.set_xlabel('absolute bw wasted')\n",
    "    dfs[cc] = df\n",
    "plt.tight_layout()\n",
    "dfs['wvegas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MP vs SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_vs_sp_df = load_iperf_experiments_new('mp_vs_sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_vs_sp_df['h2_tp_on_b'] = mp_vs_sp_df['h2_tp'] - mp_vs_sp_df['bw_a']\n",
    "# mp_vs_sp_df[['cc', 'bw_a', 'bw_b', 'h2_tp_on_b']]\n",
    "mp_vs_sp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 9.5))\n",
    "cur_df = mp_vs_sp_df[mp_vs_sp_df['bw_a'] == 15]\n",
    "cur_df['x'] = cur_df['bw_a']/cur_df['bw_b']\n",
    "cur_df = cur_df.sort_values('x')\n",
    "\n",
    "for i, cc in enumerate(mp_vs_sp_df['cc'].unique()):\n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    tmp = cur_df[cur_df['cc'] == cc]\n",
    "    \n",
    "    ax.plot(tmp['x'], tmp['h2_tp'], label='h2 (mp)')\n",
    "    ax.plot(tmp['x'], tmp['h4_tp'], label='h4 (sp)')\n",
    "    ax.plot(tmp['x'], tmp['bw_b'], label='bw_b', linestyle='dashed', c='orange')\n",
    "    ax.plot(tmp['x'], tmp['bw_a'], label='bw_a', linestyle='dashed', c='blue')\n",
    "    ax.set_title('{}'.format(cc))\n",
    "    ax.set_xlabel('bw_a / bw_b')\n",
    "    ax.set_ylabel('Mbps Throughput')\n",
    "    ax.set_ylim((0, cur_df['bw_b'].max()+1))\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9.5, 9.5))\n",
    "cur_df = mp_vs_sp_df[mp_vs_sp_df['bw_a'] == 15]\n",
    "cur_df['x'] = cur_df['bw_a']/cur_df['bw_b']\n",
    "cur_df['fair_allocation'] = cur_df[['bw_a', 'bw_b']].apply(lambda x: x[0] if x[0]>x[1] else (x[0]+x[1])/2, axis=1)\n",
    "cur_df = cur_df.sort_values('x')\n",
    "\n",
    "for i, cc in enumerate(mp_vs_sp_df['cc'].unique()):\n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    tmp = cur_df[cur_df['cc'] == cc]\n",
    "    \n",
    "    ax.plot(tmp['x'], tmp['h2_tp'] / tmp['bw_a'], label='h2 (mp)')\n",
    "    ax.plot(tmp['x'], tmp['h4_tp'] / tmp['bw_b'], label='h4 (sp)')\n",
    "    ax.plot(tmp['x'], tmp['fair_allocation'] / tmp['bw_a'], label='fair alloc', linestyle=':')\n",
    "    #ax.plot(tmp['x'], tmp['bw_b'], label='bw_b', linestyle='dashed')\n",
    "    #ax.plot(tmp['x'], tmp['bw_a'], label='bw_a', linestyle='dashed')\n",
    "    ax.set_title('{}'.format(cc))\n",
    "    ax.set_xlabel('bw_a / bw_b')\n",
    "    ax.set_ylabel('Throughput normalized')\n",
    "    ax.set_ylim((0.5, 1.5))\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "# cur_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Single Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_bottleneck_df = load_iperf_experiments_new('single_bottleneck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_bottleneck_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_plots(single_bottleneck_df)\n",
    "# de_3d_plot(single_bottleneck_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymetric MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asym_mp_df = load_iperf_experiments_new('asym_mp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asym_mp_df['total_bw'] = 15\n",
    "asym_mp_df['wasted_bw'] = asym_mp_df['total_bw'] - asym_mp_df['h2_tp'] - asym_mp_df['h4_tp'] - asym_mp_df['h6_tp']\n",
    "asym_mp_df.drop(['bw_a', 'bw_b', 'de_a', 'de_b'], axis=1).set_index('cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = asym_mp_df.copy()\n",
    "for h in ['h2', 'h4', 'h6']:\n",
    "    df['diff_to_fair_' + h] = df[h + '_tp'] - 5\n",
    "# asym_mp_df\n",
    "df = df.drop([c for c in asym_mp_df.columns if\n",
    "              not ('tp' in c or 'cc' in c or 'wasted' in c)], axis=1)\n",
    "\n",
    "\n",
    "# Plot bandwidth allocation per flow\n",
    "yerr = df.set_index('cc')[['h2_tp_conf', 'h4_tp_conf', 'h6_tp_conf']]\n",
    "ax = df.set_index('cc')[['h2_tp', 'h4_tp', 'h6_tp']].plot.barh(stacked=True)\n",
    "ax.axvline(5)\n",
    "ax.axvline(10)\n",
    "ax.axvline(15)\n",
    "\n",
    "ax.set_title('Throughput per Flow')\n",
    "ax.set_xlabel('Mbps')\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlim((0, 15.5))\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iperf_pair_tp(folder, client, server, repetitions):\n",
    "    file_name = folder + '/{}-{}_iperf.csv'\n",
    "    goodputs = []\n",
    "    \n",
    "    tp_dfs = pd.DataFrame()\n",
    "    for rep in range(repetitions):\n",
    "        cli_file = file_name.format(rep, client)\n",
    "        ser_file = file_name.format(rep, server)\n",
    "        \n",
    "        with open(cli_file, 'r') as f:\n",
    "            content = f.read().replace('iperf Done.', '').strip().splitlines()\n",
    "            recv_line = content[-1].split()\n",
    "            send_line = content[-2].split()\n",
    "            recv_tp = float(recv_line[6])\n",
    "            send_tp = float(send_line[6])\n",
    "            # error when encountering non standard unit for throughput\n",
    "            if 'Mbits' not in recv_line[7]:\n",
    "                print('ERROR: iperf reported in another unit than Mbps! See {}'.format(cli_file))\n",
    "            goodputs.append(recv_tp)\n",
    "            \n",
    "        with open(ser_file, 'r') as f:\n",
    "            content = f.read().replace('iperf3: interrupt - the server has terminated', '').strip().splitlines()\n",
    "            content = content[6:-4] # TODO replace with conditional cutting\n",
    "            df = pd.DataFrame([l.replace('[', '').replace(']','').split() for l in content],\n",
    "                             columns=['ID', 'Interval', 'Interval_unit', 'Transfer', 'Transfer_unit', 'Bandwidth', 'Bandwidth_unit'])\n",
    "            df['repetition'] = rep\n",
    "            tp_dfs = tp_dfs.append(df, ignore_index=True)\n",
    "            \n",
    "    goodputs = pd.Series(goodputs)\n",
    "    tp_dfs['client'] = client\n",
    "    tp_dfs['server'] = server\n",
    "    tp_dfs['Interval_start'] = tp_dfs['Interval'].str.split('-').str[0].astype(float)\n",
    "    tp_dfs['Interval_end'] = tp_dfs['Interval'].str.split('-').str[1].astype(float)\n",
    "    tp_dfs['ID'] = pd.to_numeric(tp_dfs['ID'])\n",
    "    tp_dfs['Transfer'] = pd.to_numeric(tp_dfs['Transfer'])\n",
    "    tp_dfs['Bandwidth'] = pd.to_numeric(tp_dfs['Bandwidth'])\n",
    "    return (goodputs.mean(), confidence_interval(goodputs)), tp_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames: ./logs/{topo}/{cc}/{0Mbps-0Mbps}/{0ms-0ms}/{rep}-{hostname}_iperf.txt\n",
    "base_path = 'logs'\n",
    "dir_path = './' + base_path + '/{}/{}/{}Mbps-{}Mbps/{}ms-{}ms/{}-'\n",
    "\n",
    "def read_flow(sender_file_name, receiver_file_name):\n",
    "    s = pd.read_csv(sender_file_name, sep='\\t')\n",
    "    r = pd.read_csv(receiver_file_name, sep='\\t')\n",
    "    # print(sender_file_name)\n",
    "    df = pd.merge(s, r, how='outer', on='pkt_id')\n",
    "    df['latency [s]'] = df['rcv_t [s]'] - df['snd_t [s]']\n",
    "    df['latency [ms]'] = (df['rcv_t [s]'] - df['snd_t [s]']) * 1000\n",
    "    df['sec'] = df['rcv_t [s]'] - df.at[(0, 'snd_t [s]')]\n",
    "    df['disk_sec'] = df['sec'].apply(np.floor)\n",
    "    df['disk_msec'] = df['sec'].apply(lambda x: np.floor(x * 1000))\n",
    "    return df\n",
    "\n",
    "def tp_array(df, bucket_size_ms=100):\n",
    "    m = int(df['disk_msec'].max() / bucket_size_ms)\n",
    "    byt, borders, _ = stats.binned_statistic(df['disk_msec'], df['payload [bytes]'], 'sum', bins=[i*bucket_size_ms for i in range(m)])\n",
    "    ndf = pd.DataFrame({'msec': borders[:-1], 'tp [Mbps]': byt * 0.008 / bucket_size_ms})\n",
    "    return ndf\n",
    "\n",
    "def mean_tp(df, cutoff_s=2):\n",
    "    latest_time = df['disk_msec'].max()\n",
    "    df = tp_array(df)\n",
    "    df = df[(df['msec'] >= cutoff_s*1e3) & (df['msec'] < latest_time - cutoff_s*1e3)]\n",
    "    return df['tp [Mbps]'].mean()\n",
    "\n",
    "def mean_latency(df, cutoff_s=2):\n",
    "    latest_time = df['disk_msec'].max()\n",
    "    df = df[(df['disk_msec'] > cutoff_s * 1000) & (df['disk_msec'] < latest_time - cutoff_s * 1000)]\n",
    "    return df['latency [ms]'].mean()\n",
    "\n",
    "# TODO enable single flow and multiflow loading\n",
    "def load_experiments(topology, cc_algorithms, tps_a, tps_b, delays_a, delays_b, repetitions=3, postfix=''):\n",
    "    df = pd.DataFrame()\n",
    "    for cc in cc_algorithms:\n",
    "        for tp_a in tps_a:\n",
    "            for tp_b in tps_b:\n",
    "                for delay_a in delays_a:\n",
    "                    for delay_b in delays_b:\n",
    "                        temp = pd.DataFrame()\n",
    "                        for rep in range(repetitions):\n",
    "                            # file name without host specified!\n",
    "                            file_name = dir_path.format(topology, cc, tp_a, tp_b, delay_a, delay_b, rep)\n",
    "                            # print(file_name + 'h2{}.txt'.format(postfix))\n",
    "                            # if os.\n",
    "                            flow1 = read_flow(file_name + 'h1{}.txt'.format(postfix), file_name + 'h2{}.txt'.format(postfix))\n",
    "                            flow2 = read_flow(file_name + 'h3{}.txt'.format(postfix), file_name + 'h4{}.txt'.format(postfix))\n",
    "                            temp = temp.append({\n",
    "                                'cc': cc,\n",
    "                                'tp_a': tp_a,\n",
    "                                'tp_b': tp_b,\n",
    "                                'delay_a': delay_a,\n",
    "                                'delay_b': delay_b,\n",
    "                                'rep': rep,\n",
    "                                'mean_tp_flow1': mean_tp(flow1),\n",
    "                                'mean_de_flow1': mean_latency(flow1),\n",
    "                                'mean_tp_flow2': mean_tp(flow2),\n",
    "                                'mean_de_flow2': mean_latency(flow2)\n",
    "                            }, ignore_index=True)\n",
    "                        # FIXME std of means is not good enough, calculate real std\n",
    "                        df = df.append({\n",
    "                            'cc': cc,\n",
    "                            'tp_a': tp_a,\n",
    "                            'tp_b': tp_b,\n",
    "                            'delay_a': delay_a,\n",
    "                            'delay_b': delay_b,\n",
    "                            'mean_tp_flow1': temp['mean_tp_flow1'].mean(),\n",
    "                            'std_tp_flow1': temp['mean_tp_flow1'].std(),\n",
    "                            'mean_de_flow1': temp['mean_de_flow1'].mean(),\n",
    "                            'std_de_flow1': temp['mean_de_flow1'].std(),\n",
    "                            'mean_tp_flow2': temp['mean_tp_flow2'].mean(),\n",
    "                            'std_tp_flow2': temp['mean_tp_flow2'].std(),\n",
    "                            'mean_de_flow2': temp['mean_de_flow2'].mean(),\n",
    "                            'std_de_flow2': temp['mean_de_flow2'].std()\n",
    "                        }, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "topologies = ['mptcp-host-pair', 'MPflow_lpkt','MPvsSP', 'MPvsSP_lpkt']\n",
    "cc_algorithms = ['lia', 'olia', 'balia', 'wvegas', 'cubic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Latency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs/mptcp-host-pair/balia/1ms-1ms/0-h1.txt\n",
    "\n",
    "topo = 'two_paths'\n",
    "\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "delays = np.arange(1, 102, 20)\n",
    "tp = 10\n",
    "\n",
    "# df = load_experiments(topo, cc_algorithms, [10], [10], delays, delays)\n",
    "\n",
    "for cc in cc_algorithms:\n",
    "    for delay_a in delays:\n",
    "        for delay_b in delays:\n",
    "            temp_df = pd.DataFrame()\n",
    "            for rep in range(1): # TODO reenable repetitions 3\n",
    "                # file name without host specified!\n",
    "                file_name = dir_path.format(topo, cc, tp, tp, delay_a, delay_b, rep)\n",
    "                flow = read_flow(file_name + 'h1.txt', file_name + 'h2.txt')\n",
    "                temp_df = temp_df.append({\n",
    "                    'cc': cc,\n",
    "                    'delay_a': delay_a,\n",
    "                    'delay_b': delay_b,\n",
    "                    'rep': rep,\n",
    "                    'mean_tp': mean_tp(flow),\n",
    "                    'mean_de': mean_latency(flow)\n",
    "                }, ignore_index=True)\n",
    "                # print(flow)\n",
    "            df = df.append({\n",
    "                'cc': cc,\n",
    "                'delay_a': delay_a,\n",
    "                'delay_b': delay_b,\n",
    "                'mean_tp': temp_df['mean_tp'].mean(),\n",
    "                'std_tp': temp_df['mean_tp'].std(),\n",
    "                'mean_de': temp_df['mean_de'].mean(),\n",
    "                'std_de': temp_df['mean_de'].std(),\n",
    "            }, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iperf csv\n",
    "# timestamp,source_address,source_port,destination_address,destination_port,interval,transferred_bytes,bits_per_second\n",
    "def read_iperf(sender_file_name, receiver_file_name):\n",
    "    header_names = ['timestamp','source_address','source_port','destination_address',\n",
    "                    'destination_port','xxx','interval','transferred_bytes','bits_per_second']\n",
    "    s = pd.read_csv(sender_file_name, names=header_names, index_col=False)\n",
    "    s['Mbps'] = s['bits_per_second'] / 1000000\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "# TODO: remove when more data is available\n",
    "def load_iperf_experiments(topology, cc_algorithms, tps_a, tps_b, delays_a, delays_b, repetitions=range(3)):\n",
    "    df = pd.DataFrame()\n",
    "    for cc in cc_algorithms:\n",
    "        for tp_a in tps_a:\n",
    "            for tp_b in tps_b:\n",
    "                for delay_a in delays_a:\n",
    "                    for delay_b in delays_b:\n",
    "                        temp = pd.DataFrame()\n",
    "                        for rep in repetitions:\n",
    "                            # file name without host specified!\n",
    "                            file_name = dir_path.format(topology, cc, tp_a, tp_b, delay_a, delay_b, rep)\n",
    "                            flow1 = read_iperf(file_name + 'h1_iperf.csv', file_name + 'h2_iperf.csv')\n",
    "                            # flow2 = read_iperf(file_name + 'h3_iperf.txt', file_name + 'h4_iperf.txt')\n",
    "                            temp = temp.append({\n",
    "                                'mean_tp_flow1': flow1['Mbps'].iloc[-1],\n",
    "                                # 'mean_tp_flow2': flow2['Mbps'],\n",
    "                                # 'mean_de_flow2': mean_latency(flow2)\n",
    "                            }, ignore_index=True)\n",
    "                        # FIXME: std of means is not good enough, calculate real std\n",
    "                        df = df.append({\n",
    "                            'cc': cc,\n",
    "                            'tp_a': tp_a,\n",
    "                            'tp_b': tp_b,\n",
    "                            'delay_a': delay_a,\n",
    "                            'delay_b': delay_b,\n",
    "                            'mean_tp_flow1': temp['mean_tp_flow1'].mean(),\n",
    "                            'std_tp_flow1': temp['mean_tp_flow1'].std(),\n",
    "                            # 'mean_de_flow1': temp['mean_de_flow1'].mean(),\n",
    "                            # 'std_de_flow1': temp['mean_de_flow1'].std(),\n",
    "                            # 'mean_tp_flow2': temp['mean_tp_flow2'].mean(),\n",
    "                            # 'std_tp_flow2': temp['mean_tp_flow2'].std(),\n",
    "                            # 'mean_de_flow2': temp['mean_de_flow2'].mean(),\n",
    "                            # 'std_de_flow2': temp['mean_de_flow2'].std()\n",
    "                        }, ignore_index=True)\n",
    "    return df\n",
    "    \n",
    "#delays = np.arange(1, 102, 20)\n",
    "#read_iperf('./logs/two_paths/lia/10Mbps-10Mbps/0ms-0ms/0-h1_iperf.txt', '')\n",
    "\n",
    "#df_iperf = load_iperf_experiments('mptcp-host-pair', cc_algorithms, [10], [10], delays, delays, repetitions=[0])\n",
    "#df_iperf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scapy.utils import\n",
    "\n",
    "def read_iperf_text(sender_file_name, receiver_file_name):\n",
    "    s = pd.Series()\n",
    "    # print(sender_file_name)\n",
    "    with open(sender_file_name, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        sender_line = lines[-4]\n",
    "        receiver_line = lines[-3]\n",
    "        # print(sender_line.split())\n",
    "        # print(receiver_line.split())\n",
    "        s['client Mbps'] = float(sender_line.split()[-4])\n",
    "        s['server Mbps'] = float(receiver_line.split()[-3])\n",
    "    #with open(receiver_file_name, 'r') as f:\n",
    "    #    lines = f.read().splitlines()\n",
    "    #    last_line = lines[-1]\n",
    "    #    # print(last_line.split(' '))\n",
    "    #    # s['server Mbps'] = float(last_line.split(' ')[-2])\n",
    "    # print(s)\n",
    "    return s\n",
    "    \n",
    "def load_iperf_experiments_txt(topology, cc_algorithms, tps_a, tps_b, delays_a, delays_b, repetitions=range(3),\n",
    "                              pcap=False):\n",
    "    df = pd.DataFrame()\n",
    "    for cc in cc_algorithms:\n",
    "        for tp_a in tps_a:\n",
    "            for tp_b in tps_b:\n",
    "                for delay_a in delays_a:\n",
    "                    for delay_b in delays_b:\n",
    "                        temp = pd.DataFrame()\n",
    "                        for rep in repetitions:\n",
    "                            # file name without host specified!\n",
    "                            file_name = dir_path.format(topology, cc, tp_a, tp_b, delay_a, delay_b, rep)\n",
    "                            flow1 = read_iperf_text(file_name + 'h1_iperf.csv', file_name + 'h2_iperf.csv')\n",
    "                            # flow2 = read_iperf(file_name + 'h3_iperf.txt', file_name + 'h4_iperf.txt')\n",
    "                            \n",
    "                            # read rtt\n",
    "                            rtt1 = None\n",
    "                            if pcap:\n",
    "                                rtt1 = read_rtt_from_pcap(file_name + 'h1_iperf_dump.pcap')\n",
    "                            \n",
    "                            temp = temp.append({\n",
    "                                'tp_flow1_c': flow1['client Mbps'],\n",
    "                                'tp_flow1': flow1['server Mbps'],\n",
    "                                'rtt_flow1': rtt1,\n",
    "                                # 'mean_tp_flow2': flow2['Mbps'],\n",
    "                                # 'mean_de_flow2': mean_latency(flow2)\n",
    "                            }, ignore_index=True)\n",
    "                        # FIXME: std of means is not good enough, calculate real std\n",
    "                        # print(temp['tp_flow1'])\n",
    "                        df = df.append({\n",
    "                            'cc': cc,\n",
    "                            'tp_a': tp_a,\n",
    "                            'tp_b': tp_b,\n",
    "                            'delay_a': delay_a,\n",
    "                            'delay_b': delay_b,\n",
    "                            'mean_tp_flow1': temp['tp_flow1'].mean(),\n",
    "                            'std_tp_flow1': temp['tp_flow1'].std(),\n",
    "                            'mean_c_tp_flow1': temp['tp_flow1_c'].mean(),\n",
    "                            'std_c_tp_flow1': temp['tp_flow1_c'].std(),\n",
    "                            'mean_rtt_flow1': temp['rtt_flow1'].mean(),\n",
    "                            # 'mean_de_flow1': temp['mean_de_flow1'].mean(),\n",
    "                            # 'std_de_flow1': temp['mean_de_flow1'].std(),\n",
    "                            # 'mean_tp_flow2': temp['mean_tp_flow2'].mean(),\n",
    "                            # 'std_tp_flow2': temp['mean_tp_flow2'].std(),\n",
    "                            # 'mean_de_flow2': temp['mean_de_flow2'].mean(),\n",
    "                            # 'std_de_flow2': temp['mean_de_flow2'].std()\n",
    "                        }, ignore_index=True)\n",
    "                break\n",
    "    return df\n",
    "\n",
    "delays = np.arange(0, 101, 20)\n",
    "\n",
    "df_iperf = load_iperf_experiments_txt('two_paths', cc_algorithms, [10], [10], delays, delays, repetitions=[0,1,2])\n",
    "df_iperf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rtt_from_pcap(file_name):\n",
    "    cmd = \"tshark -r {} -e tcp.analysis.ack_rtt -T fields\"\n",
    "    a = subprocess.Popen(['tshark', '-r', file_name, '-e', 'tcp.analysis.ack_rtt' ,'-T', 'fields'],\n",
    "                         stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    out, _ = a.communicate()\n",
    "\n",
    "    series = pd.Series(out.split(b'\\n'))\n",
    "    series = pd.to_numeric(series, errors='coerce').dropna()\n",
    "    return series.mean()\n",
    "\n",
    "# read_rtt_from_pcap('./logs/two_paths/lia/10Mbps-10Mbps/0ms-0ms/0-h1_iperf_dump.pcap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas\n",
    "## comparing different iperf runtimes\n",
    "delay_point = 40\n",
    "\n",
    "delays = np.arange(0, 102, 20)\n",
    "\n",
    "df_iperf = load_iperf_experiments_txt('two_paths', cc_algorithms, [10], [10],\n",
    "                                      [delay_point], delays, repetitions=[0,1,2])\n",
    "df_iperf_long = load_iperf_experiments_txt('two_paths_d', cc_algorithms, [10], [10],\n",
    "                                       [delay_point], delays, repetitions=[0])\n",
    "\n",
    "\n",
    "x_liperf = df_iperf_long[df_iperf_long['delay_a'] == delay_point]\n",
    "x_iperf = df_iperf[df_iperf['delay_a'] == delay_point]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5.5))\n",
    "\n",
    "for cc in x_liperf['cc'].unique():\n",
    "    tmp = x_liperf[x_liperf['cc'] == cc]\n",
    "    tmp.plot(x='delay_b', y='mean_tp_flow1', label=cc, ax=axes[0], legend=True, grid=True, ylim=(0,22))\n",
    "    # tmp.plot(x='delay_b', y='mean_c_tp_flow1', label=cc + 'c', ax=axes[0], legend=True, grid=True, ylim=(0,22))\n",
    "\n",
    "axes[0].set_title('Iperf with tcpdump but no repetitions')\n",
    "axes[0].axvline(delay_point, color='black', ls=':')\n",
    "axes[0].set_ylabel('Mbps')\n",
    "axes[0].set_xlabel('ms delay of second link')\n",
    "\n",
    "for cc in x_iperf['cc'].unique():\n",
    "    tmp = x_iperf[x_iperf['cc'] == cc]\n",
    "    tmp.plot(x='delay_b', y='mean_tp_flow1', yerr='std_tp_flow1', label=cc, ax=axes[1], legend=True, grid=True, ylim=(0,22))\n",
    "    # tmp.plot(x='delay_b', y='mean_c_tp_flow1', yerr='std_c_tp_flow1', label=cc + 'c', ax=axes[1], legend=True, grid=True, ylim=(0,22))\n",
    "    \n",
    "axes[1].set_title('Iperf test')\n",
    "axes[1].set_ylabel('Mbps')\n",
    "axes[1].axvline(delay_point, color='black', ls=':')\n",
    "axes[1].set_xlabel('ms delay of second link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas\n",
    "## comparing different iperf runtimes\n",
    "delay_point = 60\n",
    "\n",
    "delays = np.arange(0, 102, 30)\n",
    "\n",
    "#df_iperf = load_iperf_experiments_txt('two_paths', cc_algorithms, [10], [10],\n",
    "#                                      [delay_point], delays, repetitions=[0,1,2], pcap=True)\n",
    "\n",
    "x_iperf = df_iperf[df_iperf['delay_a'] == delay_point]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5.5))\n",
    "\n",
    "axes[0].set_title('Iperf Throughput')\n",
    "axes[0].axvline(delay_point, color='black', ls=':')\n",
    "axes[0].set_ylabel('Mbps')\n",
    "axes[0].set_xlabel('ms delay of second link')\n",
    "\n",
    "for cc in x_iperf['cc'].unique():\n",
    "    tmp = x_iperf[x_iperf['cc'] == cc]\n",
    "    tmp.plot(x='delay_b', y='mean_tp_flow1', yerr='std_tp_flow1', label=cc, ax=axes[0], legend=True, grid=True, ylim=(0,22))\n",
    "    tmp.plot(x='delay_b', y='mean_rtt_flow1', label=cc, ax=axes[1], legend=True, grid=True)\n",
    "    # tmp.plot(x='delay_b', y='mean_c_tp_flow1', yerr='std_c_tp_flow1', label=cc + 'c', ax=axes[1], legend=True, grid=True, ylim=(0,22))\n",
    "    \n",
    "axes[1].set_title('Iperf rtt')\n",
    "axes[1].set_ylabel('s')\n",
    "axes[1].axvline(delay_point, color='black', ls=':')\n",
    "axes[1].set_xlabel('ms delay of second link')\n",
    "\n",
    "#df_iperf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with delay comparison which is not yet working\n",
    "\n",
    "import matplotlib\n",
    "import pandas\n",
    "## comparing different iperf runtimes\n",
    "delay_point = 40\n",
    "\n",
    "delays = np.arange(0, 102, 20)\n",
    "\n",
    "df_iperf = load_iperf_experiments_txt('two_paths', cc_algorithms, [10], [10],\n",
    "                                      [delay_point], delays, repetitions=[0,1,2])\n",
    "df_iperf_long = load_iperf_experiments_txt('two_paths_d', cc_algorithms, [10], [10],\n",
    "                                       [delay_point], delays, repetitions=[0])\n",
    "\n",
    "\n",
    "x_liperf = df_iperf_long[df_iperf_long['delay_a'] == delay_point]\n",
    "x_iperf = df_iperf[df_iperf['delay_a'] == delay_point]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 5.5))\n",
    "\n",
    "for cc in x_liperf['cc'].unique():\n",
    "    tmp = x_liperf[x_liperf['cc'] == cc]\n",
    "    tmp.plot(x='delay_b', y='mean_tp_flow1', label=cc, ax=axes[0,0], legend=True, grid=True, ylim=(0,22))\n",
    "    # tmp.plot(x='delay_b', y='mean_c_tp_flow1', label=cc + 'c', ax=axes[0], legend=True, grid=True, ylim=(0,22))\n",
    "    tmp.plot(x='delay_b', y='mean_rtt_flow1', label=cc, ax=axes[1,0], legend=True, grid=True, ylim=(0,22))\n",
    "\n",
    "axes[0,0].set_title('Iperf with tcpdump but no repetitions')\n",
    "axes[0,0].axvline(delay_point, color='black', ls=':')\n",
    "axes[0,0].set_ylabel('Mbps')\n",
    "axes[0,0].set_xlabel('ms delay of second link')\n",
    "\n",
    "for cc in x_iperf['cc'].unique():\n",
    "    tmp = x_iperf[x_iperf['cc'] == cc]\n",
    "    tmp.plot(x='delay_b', y='mean_tp_flow1', yerr='std_tp_flow1', label=cc, ax=axes[0,1], legend=True, grid=True, ylim=(0,22))\n",
    "    # tmp.plot(x='delay_b', y='mean_c_tp_flow1', yerr='std_c_tp_flow1', label=cc + 'c', ax=axes[1], legend=True, grid=True, ylim=(0,22))\n",
    "    # tmp.plot(x='delay_b', y='mean_rtt_flow1', label=cc, ax=axes[1,1], legend=True, grid=True, ylim=(0,22))\n",
    "    \n",
    "axes[0,1].set_title('Iperf test')\n",
    "axes[0,1].set_ylabel('Mbps')\n",
    "axes[0,1].axvline(delay_point, color='black', ls=':')\n",
    "axes[0,1].set_xlabel('ms delay of second link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparing different iperf runtimes\n",
    "def plot(delay_point=0):\n",
    "    #delay_point = 20\n",
    "\n",
    "    delays = np.arange(0, 102, 20)\n",
    "\n",
    "    df_iperf = load_iperf_experiments_txt('two_paths', cc_algorithms, [10], [10],\n",
    "                                          [delay_point], delays, repetitions=[0,1,2])\n",
    "    df_iperf_long = load_iperf_experiments('two_paths_m', cc_algorithms, [10], [10],\n",
    "                                          [delay_point], np.arange(0, 101, 10), repetitions=[0,1,2])\n",
    "\n",
    "\n",
    "    x_liperf = df_iperf_long[df_iperf_long['delay_a'] == delay_point]\n",
    "    x_iperf = df_iperf[df_iperf['delay_a'] == delay_point]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5.5))\n",
    "\n",
    "    for cc in x_liperf['cc'].unique():\n",
    "        tmp = x_liperf[x_liperf['cc'] == cc]\n",
    "        tmp.plot(x='delay_b', y='mean_tp_flow1', yerr='std_tp_flow1', capsize=5, label=cc, ax=axes[0], legend=True, grid=True, ylim=(0,22))\n",
    "\n",
    "    axes[0].set_title('Iperf smaller steps')\n",
    "    axes[0].axvline(delay_point, color='black', ls=':')\n",
    "    axes[0].set_ylabel('Mbps')\n",
    "    axes[0].set_xlabel('ms delay of second link')\n",
    "\n",
    "    for cc in x_iperf['cc'].unique():\n",
    "        tmp = x_iperf[x_iperf['cc'] == cc]\n",
    "        tmp.plot(x='delay_b', y='mean_tp_flow1', yerr='std_tp_flow1', capsize=5, label=cc, ax=axes[1], legend=True, grid=True, ylim=(0,22))\n",
    "\n",
    "    axes[1].set_title('Iperf')\n",
    "    axes[1].set_ylabel('Mbps')\n",
    "    axes[1].axvline(delay_point, color='black', ls=':')\n",
    "    axes[1].set_xlabel('ms delay of second link')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
